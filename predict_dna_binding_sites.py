#!/usr/bin/env python3
"""
å®Œæ•´çš„DNAç»“åˆä½ç‚¹é¢„æµ‹å’Œå¯è§†åŒ–è„šæœ¬

åŠŸèƒ½:
1. ä»è›‹ç™½è´¨åºåˆ—æå–ESM-2ç‰¹å¾
2. ä½¿ç”¨è®­ç»ƒå¥½çš„GNNæ¨¡å‹é¢„æµ‹DNAç»“åˆä½ç‚¹
3. ç”ŸæˆPyMOLå¯è§†åŒ–è„šæœ¬
4. æ”¯æŒDNA-573å’ŒDNA-646ä¸¤ä¸ªè®­ç»ƒæ¨¡å‹

ä½œè€…: Advanced GAT-GNN DNA Binding Site Predictor
æ—¥æœŸ: 2025
"""

import os
import sys
import json
import argparse
import numpy as np
import torch
import torch.nn.functional as F
from torch_geometric.data import Data
from datetime import datetime

# æ·»åŠ å½“å‰ç›®å½•åˆ°è·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, current_dir)

# å¯¼å…¥æ¨¡å‹
from advanced_gnn_model import AdvancedBindingSiteGNN


class DNABindingSitePredictor:
    """DNAç»“åˆä½ç‚¹é¢„æµ‹å™¨"""

    def __init__(self, model_path, device='cuda'):
        """
        åˆå§‹åŒ–é¢„æµ‹å™¨

        Args:
            model_path: è®­ç»ƒå¥½çš„æ¨¡å‹è·¯å¾„
            device: è®¡ç®—è®¾å¤‡ ('cuda' or 'cpu')
        """
        self.device = torch.device(device if torch.cuda.is_available() else 'cpu')
        print(f"ğŸ”§ ä½¿ç”¨è®¾å¤‡: {self.device}")

        # åŠ è½½æ¨¡å‹
        print(f"ğŸ“¥ åŠ è½½æ¨¡å‹: {model_path}")
        checkpoint = torch.load(model_path, map_location=self.device)

        # è·å–æ¨¡å‹é…ç½®
        if isinstance(checkpoint, dict) and 'model_config' in checkpoint:
            model_config = checkpoint['model_config']
            self.model = AdvancedBindingSiteGNN(**model_config)
            self.model.load_state_dict(checkpoint['model_state_dict'])
            print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ (ä½¿ç”¨ä¿å­˜çš„é…ç½®)")
        else:
            # ä½¿ç”¨é»˜è®¤é…ç½®
            self.model = AdvancedBindingSiteGNN(
                input_dim=1280,  # ESM-2ç‰¹å¾ç»´åº¦
                hidden_dim=256,
                num_layers=4,
                heads=4,
                dropout=0.3,
                use_edge_features=True
            )
            if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:
                self.model.load_state_dict(checkpoint['model_state_dict'])
            else:
                self.model.load_state_dict(checkpoint)
            print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ (ä½¿ç”¨é»˜è®¤é…ç½®)")

        self.model = self.model.to(self.device)
        self.model.eval()

        # åŠ è½½ESM-2æ¨¡å‹
        print(f"ğŸ“¥ åŠ è½½ESM-2æ¨¡å‹...")
        try:
            from transformers import AutoTokenizer, AutoModel
            model_name = "facebook/esm2_t33_650M_UR50D"
            # ä½¿ç”¨local_files_only=Trueä¼˜å…ˆä½¿ç”¨æœ¬åœ°ç¼“å­˜
            self.esm_tokenizer = AutoTokenizer.from_pretrained(model_name, local_files_only=True)
            self.esm_model = AutoModel.from_pretrained(model_name, local_files_only=True)
            self.esm_model = self.esm_model.to(self.device)
            self.esm_model.eval()
            print(f"âœ… ESM-2æ¨¡å‹åŠ è½½æˆåŠŸ (ä½¿ç”¨æœ¬åœ°ç¼“å­˜)")
        except Exception as e:
            print(f"âŒ ESM-2æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            print("è¯·å®‰è£…transformers: pip install transformers")
            print("æˆ–é¦–æ¬¡è¿è¡Œéœ€è¦ä¸‹è½½ESM-2æ¨¡å‹ï¼ˆ~2.5GBï¼‰")
            raise

    def extract_esm2_features(self, sequence):
        """
        ä»è›‹ç™½è´¨åºåˆ—æå–ESM-2ç‰¹å¾

        Args:
            sequence: è›‹ç™½è´¨åºåˆ—å­—ç¬¦ä¸²

        Returns:
            features: (seq_len, 1280) æ¯ä¸ªæ®‹åŸºçš„ç‰¹å¾å‘é‡
        """
        print(f"ğŸ§¬ æå–ESM-2ç‰¹å¾ (åºåˆ—é•¿åº¦: {len(sequence)})")

        with torch.no_grad():
            # åˆ†è¯
            inputs = self.esm_tokenizer(
                sequence,
                return_tensors="pt",
                padding=False,
                truncation=True,
                max_length=1024
            )
            inputs = {k: v.to(self.device) for k, v in inputs.items()}

            # è·å–æ¨¡å‹è¾“å‡º
            outputs = self.esm_model(**inputs, output_hidden_states=True)

            # ä½¿ç”¨æœ€åä¸€å±‚çš„éšè—çŠ¶æ€
            # Shape: (1, seq_len+2, 1280) - +2æ˜¯å› ä¸ºæœ‰<cls>å’Œ<eos> token
            last_hidden = outputs.last_hidden_state

            # å»æ‰ç‰¹æ®Štokenï¼Œåªä¿ç•™åºåˆ—éƒ¨åˆ†
            # [0, 1:-1] -> å»æ‰batchç»´åº¦ï¼Œå»æ‰<cls>å’Œ<eos>
            sequence_features = last_hidden[0, 1:-1, :].cpu().numpy()

        print(f"âœ… ç‰¹å¾æå–å®Œæˆ: {sequence_features.shape}")
        return sequence_features

    def build_graph_from_sequence(self, sequence_features, k_neighbors=10):
        """
        ä»åºåˆ—ç‰¹å¾æ„å»ºå›¾

        Args:
            sequence_features: (seq_len, 1280) ç‰¹å¾çŸ©é˜µ
            k_neighbors: KNNæ„å»ºè¾¹çš„é‚»å±…æ•°

        Returns:
            data: PyG Dataå¯¹è±¡
        """
        seq_len = sequence_features.shape[0]

        # èŠ‚ç‚¹ç‰¹å¾
        x = torch.tensor(sequence_features, dtype=torch.float32)

        # æ„å»ºè¾¹: ä½¿ç”¨åºåˆ—ä½ç½® + KNN
        edge_index = []

        # 1. åºåˆ—é‚»æ¥è¾¹ (i, i+1)
        for i in range(seq_len - 1):
            edge_index.append([i, i+1])
            edge_index.append([i+1, i])

        # 2. KNNè¾¹ (åŸºäºç‰¹å¾ç›¸ä¼¼åº¦)
        from sklearn.neighbors import NearestNeighbors
        nbrs = NearestNeighbors(n_neighbors=min(k_neighbors, seq_len), algorithm='auto')
        nbrs.fit(sequence_features)
        distances, indices = nbrs.kneighbors(sequence_features)

        for i in range(seq_len):
            for j in indices[i][1:]:  # è·³è¿‡è‡ªå·±
                if i != j:
                    edge_index.append([i, j])

        # è½¬æ¢ä¸ºtensor
        if len(edge_index) > 0:
            edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()
        else:
            edge_index = torch.empty((2, 0), dtype=torch.long)

        # åˆ›å»ºDataå¯¹è±¡å¹¶æ·»åŠ batchä¿¡æ¯ï¼ˆå•ä¸ªå›¾ï¼Œæ‰€æœ‰èŠ‚ç‚¹batch=0ï¼‰
        batch = torch.zeros(seq_len, dtype=torch.long)
        data = Data(x=x, edge_index=edge_index, batch=batch)

        print(f"ğŸ“Š å›¾æ„å»ºå®Œæˆ: {seq_len} èŠ‚ç‚¹, {edge_index.shape[1]} æ¡è¾¹")
        return data

    def predict(self, sequence, threshold=0.5, k_neighbors=10):
        """
        é¢„æµ‹DNAç»“åˆä½ç‚¹

        Args:
            sequence: è›‹ç™½è´¨åºåˆ—
            threshold: åˆ†ç±»é˜ˆå€¼
            k_neighbors: å›¾æ„å»ºçš„é‚»å±…æ•°

        Returns:
            predictions: (seq_len,) é¢„æµ‹æ¦‚ç‡
            binding_sites: (seq_len,) äºŒå€¼æ ‡ç­¾ (0/1)
        """
        # 1. æå–ESM-2ç‰¹å¾
        features = self.extract_esm2_features(sequence)

        # 2. æ„å»ºå›¾
        data = self.build_graph_from_sequence(features, k_neighbors=k_neighbors)
        data = data.to(self.device)

        # 3. æ¨¡å‹é¢„æµ‹
        print(f"ğŸ”® å¼€å§‹é¢„æµ‹...")
        with torch.no_grad():
            logits = self.model(data)
            probs = torch.sigmoid(logits).cpu().numpy()

        # 4. é˜ˆå€¼åŒ–
        binding_sites = (probs >= threshold).astype(int)

        num_binding = binding_sites.sum()
        ratio = num_binding / len(sequence) * 100

        print(f"âœ… é¢„æµ‹å®Œæˆ!")
        print(f"   â€¢ åºåˆ—é•¿åº¦: {len(sequence)}")
        print(f"   â€¢ ç»“åˆä½ç‚¹: {num_binding} ({ratio:.1f}%)")
        print(f"   â€¢ éç»“åˆä½ç‚¹: {len(sequence) - num_binding} ({100-ratio:.1f}%)")

        return probs, binding_sites


def generate_pymol_script(sequence, predictions, binding_sites,
                         output_file, pdb_id=None, pdb_file=None,
                         high_conf_threshold=0.7, low_conf_threshold=0.5):
    """
    ç”ŸæˆPyMOLå¯è§†åŒ–è„šæœ¬

    Args:
        sequence: è›‹ç™½è´¨åºåˆ—
        predictions: é¢„æµ‹æ¦‚ç‡
        binding_sites: äºŒå€¼æ ‡ç­¾
        output_file: è¾“å‡º.pmlæ–‡ä»¶è·¯å¾„
        pdb_id: PDB ID (å¦‚æœæœ‰)
        pdb_file: æœ¬åœ°PDBæ–‡ä»¶è·¯å¾„
        high_conf_threshold: é«˜ç½®ä¿¡åº¦é˜ˆå€¼
        low_conf_threshold: ä½ç½®ä¿¡åº¦é˜ˆå€¼
    """
    script = []

    # åŠ è½½ç»“æ„
    script.append("# DNA Binding Site Visualization")
    script.append("# Generated by Advanced GAT-GNN Predictor\n")

    if pdb_file:
        script.append(f"load {pdb_file}, protein")
    elif pdb_id:
        script.append(f"fetch {pdb_id}, protein")
    else:
        script.append("# No structure provided - please load manually")
        script.append("# load your_structure.pdb, protein\n")

    # åŸºç¡€è®¾ç½®
    script.append("\n# Basic settings")
    script.append("bg_color white")
    script.append("hide everything")
    script.append("show cartoon, protein")
    script.append("color gray80, protein")
    script.append("set cartoon_fancy_helices, 1")
    script.append("set cartoon_smooth_loops, 1\n")

    # æŒ‰ç½®ä¿¡åº¦åˆ†ç±»æ®‹åŸº
    high_conf_residues = []
    medium_conf_residues = []
    low_conf_residues = []

    for i, (pred, is_binding) in enumerate(zip(predictions, binding_sites)):
        if is_binding:
            residue_num = i + 1  # æ®‹åŸºç¼–å·ä»1å¼€å§‹
            if pred >= high_conf_threshold:
                high_conf_residues.append(residue_num)
            elif pred >= low_conf_threshold:
                medium_conf_residues.append(residue_num)
            else:
                low_conf_residues.append(residue_num)

    # åˆ›å»ºé€‰æ‹©å’Œç€è‰²
    script.append("# DNA binding sites\n")

    if high_conf_residues:
        residues_str = "+".join(map(str, high_conf_residues))
        script.append(f"# High confidence binding sites ({len(high_conf_residues)} residues)")
        script.append(f"select high_conf, resi {residues_str}")
        script.append("color red, high_conf")
        script.append("show sticks, high_conf")
        script.append("show spheres, high_conf")
        script.append("set sphere_scale, 0.3, high_conf\n")

    if medium_conf_residues:
        residues_str = "+".join(map(str, medium_conf_residues))
        script.append(f"# Medium confidence binding sites ({len(medium_conf_residues)} residues)")
        script.append(f"select medium_conf, resi {residues_str}")
        script.append("color orange, medium_conf")
        script.append("show sticks, medium_conf")
        script.append("show spheres, medium_conf")
        script.append("set sphere_scale, 0.25, medium_conf\n")

    if low_conf_residues:
        residues_str = "+".join(map(str, low_conf_residues))
        script.append(f"# Low confidence binding sites ({len(low_conf_residues)} residues)")
        script.append(f"select low_conf, resi {residues_str}")
        script.append("color yellow, low_conf")
        script.append("show sticks, low_conf\n")

    # è§†å›¾è®¾ç½®
    script.append("# View settings")
    script.append("orient")
    script.append("zoom protein")
    script.append("set ray_shadows, 0")
    script.append("set antialias, 2")
    script.append("set orthoscopic, on\n")

    # æ ‡ç­¾
    script.append("# Labels")
    script.append("set label_size, 20")
    script.append("set label_color, black\n")

    # å›¾ä¾‹
    script.append("# Legend")
    script.append("# Red: High confidence (p >= {:.2f})".format(high_conf_threshold))
    script.append("# Orange: Medium confidence ({:.2f} <= p < {:.2f})".format(low_conf_threshold, high_conf_threshold))
    script.append("# Yellow: Low confidence (p < {:.2f})".format(low_conf_threshold))
    script.append("# Gray: Non-binding sites\n")

    # ä¿å­˜è„šæœ¬
    with open(output_file, 'w') as f:
        f.write('\n'.join(script))

    print(f"âœ… PyMOLè„šæœ¬å·²ä¿å­˜: {output_file}")


def save_results(sequence, predictions, binding_sites, output_dir, seq_id=None):
    """
    ä¿å­˜é¢„æµ‹ç»“æœ

    Args:
        sequence: è›‹ç™½è´¨åºåˆ—
        predictions: é¢„æµ‹æ¦‚ç‡
        binding_sites: äºŒå€¼æ ‡ç­¾
        output_dir: è¾“å‡ºç›®å½•
        seq_id: åºåˆ—ID
    """
    os.makedirs(output_dir, exist_ok=True)

    seq_id = seq_id or "unknown"
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

    # 1. JSONæ ¼å¼ (è¯¦ç»†)
    json_file = os.path.join(output_dir, f"{seq_id}_predictions.json")
    results = {
        'sequence_id': seq_id,
        'sequence': sequence,
        'sequence_length': len(sequence),
        'predictions': predictions.tolist(),
        'binding_sites': binding_sites.tolist(),
        'num_binding_sites': int(binding_sites.sum()),
        'binding_ratio': float(binding_sites.sum() / len(sequence)),
        'timestamp': timestamp
    }

    with open(json_file, 'w') as f:
        json.dump(results, f, indent=2)
    print(f"âœ… JSONç»“æœå·²ä¿å­˜: {json_file}")

    # 2. æ–‡æœ¬æ ¼å¼ (äººç±»å¯è¯»)
    txt_file = os.path.join(output_dir, f"{seq_id}_predictions.txt")
    with open(txt_file, 'w') as f:
        f.write(f"DNA Binding Site Predictions\n")
        f.write(f"=" * 80 + "\n\n")
        f.write(f"Sequence ID: {seq_id}\n")
        f.write(f"Sequence Length: {len(sequence)}\n")
        f.write(f"Binding Sites: {binding_sites.sum()} ({binding_sites.sum()/len(sequence)*100:.1f}%)\n")
        f.write(f"Timestamp: {timestamp}\n\n")

        f.write(f"{'Position':<10} {'Residue':<10} {'Prediction':<12} {'Binding':<10}\n")
        f.write(f"{'-'*50}\n")

        for i, (aa, pred, is_binding) in enumerate(zip(sequence, predictions, binding_sites)):
            pos = i + 1
            binding_str = "YES" if is_binding else "no"
            f.write(f"{pos:<10} {aa:<10} {pred:.4f}      {binding_str:<10}\n")

    print(f"âœ… æ–‡æœ¬ç»“æœå·²ä¿å­˜: {txt_file}")

    # 3. FASTAæ ¼å¼ (å¸¦æ ‡ç­¾)
    fasta_file = os.path.join(output_dir, f"{seq_id}_annotated.fasta")
    with open(fasta_file, 'w') as f:
        f.write(f">{seq_id} | DNA binding sites\n")
        f.write(f"{sequence}\n")
        f.write(f">Binding_sites (1=binding, 0=non-binding)\n")
        f.write(f"{''.join(map(str, binding_sites))}\n")
        f.write(f">Prediction_scores\n")
        for pred in predictions:
            f.write(f"{pred:.3f} ")
        f.write("\n")

    print(f"âœ… FASTAç»“æœå·²ä¿å­˜: {fasta_file}")

    return {
        'json': json_file,
        'txt': txt_file,
        'fasta': fasta_file
    }


def main():
    parser = argparse.ArgumentParser(
        description="é¢„æµ‹è›‹ç™½è´¨åºåˆ—çš„DNAç»“åˆä½ç‚¹å¹¶ç”ŸæˆPyMOLå¯è§†åŒ–è„šæœ¬",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  # ä»FASTAæ–‡ä»¶é¢„æµ‹ (ä½¿ç”¨DNA-573æ¨¡å‹)
  python predict_dna_binding_sites.py --fasta protein.fasta --model dna573

  # ä»åºåˆ—å­—ç¬¦ä¸²é¢„æµ‹ (ä½¿ç”¨DNA-646æ¨¡å‹)
  python predict_dna_binding_sites.py --sequence "MKLAVLV..." --model dna646

  # æŒ‡å®šè‡ªå®šä¹‰æ¨¡å‹è·¯å¾„
  python predict_dna_binding_sites.py --fasta protein.fasta --model-path /path/to/model.pt

  # ç”ŸæˆPyMOLè„šæœ¬ (ä½¿ç”¨PDB ID)
  python predict_dna_binding_sites.py --fasta protein.fasta --pdb-id 1ABC

  # ç”ŸæˆPyMOLè„šæœ¬ (ä½¿ç”¨æœ¬åœ°PDBæ–‡ä»¶)
  python predict_dna_binding_sites.py --fasta protein.fasta --pdb-file protein.pdb
        """
    )

    # è¾“å…¥é€‰é¡¹
    input_group = parser.add_mutually_exclusive_group(required=True)
    input_group.add_argument('--fasta', type=str, help='FASTAæ–‡ä»¶è·¯å¾„')
    input_group.add_argument('--sequence', type=str, help='è›‹ç™½è´¨åºåˆ—å­—ç¬¦ä¸²')

    # æ¨¡å‹é€‰é¡¹
    model_group = parser.add_mutually_exclusive_group(required=True)
    model_group.add_argument('--model', type=str, choices=['dna573', 'dna646'],
                           help='ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹: dna573 æˆ– dna646')
    model_group.add_argument('--model-path', type=str,
                           help='è‡ªå®šä¹‰æ¨¡å‹è·¯å¾„')

    # é¢„æµ‹å‚æ•°
    parser.add_argument('--threshold', type=float, default=0.5,
                       help='åˆ†ç±»é˜ˆå€¼ (é»˜è®¤: 0.5)')
    parser.add_argument('--k-neighbors', type=int, default=10,
                       help='å›¾æ„å»ºçš„KNNé‚»å±…æ•° (é»˜è®¤: 10)')

    # PyMOLå¯è§†åŒ–
    parser.add_argument('--pdb-id', type=str, help='PDB ID (ç”¨äºPyMOLå¯è§†åŒ–)')
    parser.add_argument('--pdb-file', type=str, help='æœ¬åœ°PDBæ–‡ä»¶è·¯å¾„')

    # è¾“å‡ºé€‰é¡¹
    parser.add_argument('--output-dir', type=str, default='prediction_results',
                       help='è¾“å‡ºç›®å½• (é»˜è®¤: prediction_results)')
    parser.add_argument('--seq-id', type=str, help='åºåˆ—ID (ç”¨äºè¾“å‡ºæ–‡ä»¶å‘½å)')

    # è®¾å¤‡é€‰é¡¹
    parser.add_argument('--device', type=str, default='cuda',
                       choices=['cuda', 'cpu'], help='è®¡ç®—è®¾å¤‡ (é»˜è®¤: cuda)')

    args = parser.parse_args()

    # æ‰“å°æ ‡é¢˜
    print("=" * 80)
    print("ğŸ§¬ DNAç»“åˆä½ç‚¹é¢„æµ‹å™¨ - Advanced GAT-GNN")
    print("=" * 80)
    print()

    # 1. åŠ è½½åºåˆ—
    if args.fasta:
        print(f"ğŸ“– ä»FASTAæ–‡ä»¶åŠ è½½åºåˆ—: {args.fasta}")
        with open(args.fasta, 'r') as f:
            lines = f.readlines()

        sequence = ""
        seq_id = None
        for line in lines:
            line = line.strip()
            if line.startswith('>'):
                if seq_id is None:  # åªè¯»å–ç¬¬ä¸€æ¡åºåˆ—
                    seq_id = line[1:].split()[0]
            else:
                if all(c in '01' for c in line):  # è·³è¿‡æ ‡ç­¾è¡Œ
                    continue
                sequence += line

        if not sequence:
            print("âŒ é”™è¯¯: FASTAæ–‡ä»¶ä¸­æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆåºåˆ—")
            return

        seq_id = args.seq_id or seq_id or "unknown"
        print(f"âœ… åºåˆ—åŠ è½½æˆåŠŸ")
        print(f"   â€¢ ID: {seq_id}")
        print(f"   â€¢ é•¿åº¦: {len(sequence)}")
    else:
        sequence = args.sequence
        seq_id = args.seq_id or "custom_sequence"
        print(f"âœ… ä½¿ç”¨æä¾›çš„åºåˆ— (é•¿åº¦: {len(sequence)})")

    # 2. ç¡®å®šæ¨¡å‹è·¯å¾„
    if args.model_path:
        model_path = args.model_path
    else:
        base_dir = "/mnt/data2/Yang/zhq_pro/method2_ppi_training/Augmented_data_balanced"
        if args.model == 'dna573':
            model_path = os.path.join(base_dir, "DNA-573_Train_ultimate_r050/ultimate_gnn_model.pt")
        else:  # dna646
            model_path = os.path.join(base_dir, "DNA-646_Train_ultimate_r050/ultimate_gnn_model.pt")

    if not os.path.exists(model_path):
        print(f"âŒ é”™è¯¯: æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        return

    print(f"\nğŸ“Š ä½¿ç”¨æ¨¡å‹: {model_path}")

    # 3. åˆ›å»ºé¢„æµ‹å™¨
    try:
        predictor = DNABindingSitePredictor(model_path, device=args.device)
    except Exception as e:
        print(f"âŒ é¢„æµ‹å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
        return

    # 4. é¢„æµ‹
    print(f"\n{'='*80}")
    try:
        predictions, binding_sites = predictor.predict(
            sequence,
            threshold=args.threshold,
            k_neighbors=args.k_neighbors
        )
    except Exception as e:
        print(f"âŒ é¢„æµ‹å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return

    # 5. ä¿å­˜ç»“æœ
    print(f"\n{'='*80}")
    print(f"ğŸ’¾ ä¿å­˜ç»“æœ...")
    output_files = save_results(sequence, predictions, binding_sites, args.output_dir, seq_id)

    # 6. ç”ŸæˆPyMOLè„šæœ¬
    if args.pdb_id or args.pdb_file:
        print(f"\nğŸ“Š ç”ŸæˆPyMOLå¯è§†åŒ–è„šæœ¬...")
        pml_file = os.path.join(args.output_dir, f"{seq_id}_visualization.pml")
        generate_pymol_script(
            sequence, predictions, binding_sites,
            pml_file,
            pdb_id=args.pdb_id,
            pdb_file=args.pdb_file
        )
        print(f"\nğŸ’¡ ä½¿ç”¨PyMOLå¯è§†åŒ–:")
        print(f"   pymol {pml_file}")

    # æ€»ç»“
    print(f"\n{'='*80}")
    print(f"âœ… é¢„æµ‹å®Œæˆ!")
    print(f"\nğŸ“ è¾“å‡ºæ–‡ä»¶:")
    for key, path in output_files.items():
        print(f"   â€¢ {key.upper()}: {path}")
    if args.pdb_id or args.pdb_file:
        print(f"   â€¢ PyMOL: {pml_file}")
    print(f"\n{'='*80}")


if __name__ == "__main__":
    main()
